# ğŸ“Š EstadÃ­stica

Repositorio de conceptos fundamentales y avanzados de estadÃ­stica para el anÃ¡lisis de datos. He intentado responde lo mejor posible a las preguntas, segÃºn entiendo yo los conceptos y sus aplicaciones. Como siempre, si alguien no estÃ¡ de acuerdo en alguna respuesta, comunicadlo!

### ğŸ—ºï¸ NavegaciÃ³n RÃ¡pida

[![](https://img.shields.io/badge/Nivel-FÃ¡cil-brightgreen?style=for-the-badge)](#-nivel-fÃ¡cil)
[![](https://img.shields.io/badge/Nivel-Intermedio-yellow?style=for-the-badge)](#-nivel-intermedio)
[![](https://img.shields.io/badge/Nivel-DifÃ­cil-red?style=for-the-badge)](#-nivel-difÃ­cil)

---

## ğŸŸ¢ Nivel: FÃ¡cil

### ğŸ“– Explica el Teorema del LÃ­mite Central. Â¿Por quÃ© es Ãºtil?
<details>
  <summary><b>Ver respuesta ğŸ”‘</b></summary>

  El teorema del lÃ­mite central sostiene que si extraemos muestras de la poblaciÃ³n un gran nÃºmero de veces, la distribuciÃ³n de las medias de dichas muestras tendrÃ¡ una forma cercana a la normal, independientemente de si la distribuciÃ³n original lo es.
  
  

  Entre sus principales utilidades destacan:
  * **Facilita la inferencia estadÃ­stica** â†’ permite tratar a los promedios de las muestras como si tuvieran una distribuciÃ³n normal, incluso si no conocemos la distribuciÃ³n real de la poblaciÃ³n, lo que es vital para realizar estimaciones y pruebas de hipÃ³tesis.
</details>

### ğŸ“– Â¿CÃ³mo explicarÃ­as los intervalos de confianza a una audiencia no tÃ©cnica?
<details>
  <summary><b>Ver respuesta ğŸ”‘</b></summary>

  Imaginamos que queremos saber el peso promedio de todos los osos de un parque nacional, pero es imposible pesarlos a todos. Para resolverlo, pesamos a unos pocos (muestra) y calculamos el promedio. Sin embargo, sabemos que ese nÃºmero no es exacto para toda la poblaciÃ³n, puesto que es solo una estimaciÃ³n. AquÃ­ es donde entran los intervalos de confianza.
  
  El nivel de confianza (95% por ejemplo) indica que nuestro mÃ©todo es confiable: si repitiÃ©ramos el experimento muchas veces y calculÃ¡ramos un nuevo intervalo cada vez, el 95% de esos intervalos contendrÃ­an el valor real.
  
  El nivel de confianza se determina por un margen de error establecido con anterioridad al experimento. Cuanto mÃ¡s estrecho se hace el umbral, mÃ¡s precisa se hace la estimaciÃ³n, puesto que implica una menor incertidumbre (puedo asegurar gracias a la calidad de mis datos que el valor real estarÃ¡ dentro de un rango mÃ¡s pequeÃ±o).
</details>

### ğŸ“– Explica la covarianza y la correlaciÃ³n y compÃ¡ralas.
<details>
  <summary><b>Ver respuesta ğŸ”‘</b></summary>

  La covarianza es una medida que nos indica si dos variables se mueven en la misma direcciÃ³n (si una aumenta la otra tambiÃ©n y viceversa). Una covarianza positiva serÃ¡ la relaciÃ³n entre el peso y la altura (por lo general, si alguien es mÃ¡s alto, tambiÃ©n tiende a pesar mÃ¡s).
  
  La covarianza tiene el problema de que depende totalmente de las unidades de medida. Si medimos la altura en metros o en centÃ­metros, el nÃºmero de la covarianza cambiarÃ¡ drÃ¡sticamente, lo que hace que sea muy difÃ­cil saber si una relaciÃ³n es â€œfuerteâ€ o â€œdÃ©bilâ€.
  
  AhÃ­ es donde entra la correlaciÃ³n. La correlaciÃ³n es bÃ¡sicamente una covarianza estandarizada, que podemos utilizar para comparar cualquier variable con una escala fija entre 1 y -1. AdemÃ¡s, nos indica quÃ© tan estrecha es la relaciÃ³n entre las variables, cuanto mÃ¡s cerca se encuentre el valor de 1 y -1.

  

  | CaracterÃ­stica | Covarianza | CorrelaciÃ³n |
  | :--- | :--- | :--- |
  | **Â¿QuÃ© mide?** | La direcciÃ³n de la relaciÃ³n (si suben o bajan juntas). | La direcciÃ³n y la fuerza de la relaciÃ³n. |
  | **Escala** | No tiene lÃ­mites (puede ser cualquier nÃºmero). | Limitada estrictamente entre -1 y +1. |
  | **Unidades** | Depende de las unidades de las variables (kilos x metros). | No tiene unidades; es un nÃºmero puro. |
  | **Utilidad** | Ãštil para cÃ¡lculos matemÃ¡ticos internos en modelos complejos. | La mejor tÃ©cnica para estimar visualmente quÃ© tan relacionadas estÃ¡n dos cosas. |
</details>

### ğŸ“– Â¿CuÃ¡les son algunos de los peligros / dificultades comunes en el test A/B?
<details>
  <summary><b>Ver respuesta ğŸ”‘</b></summary>

  Los principales peligros y dificultades del test estadÃ­stico son los siguientes:
  * **Errores del Tipo I y Tipo II:** cometer un falso positivo que ocurre cuando se rechaza la hipÃ³tesis nula (se cree que hay un efecto) a pesar de que la conjetura es falsa. Cometer un falso negativo, que sucede cuando la conjetura es vÃ¡lida, pero no se logra rechazar la hipÃ³tesis nula.
  * **Problema de las pruebas mÃºltiples:** al realizar muchas pruebas de hipÃ³tesis simultÃ¡neas, la probabilidad de obtener al menos un falso positivo aumenta drÃ¡sticamente.
  * **Calidad y relevancia de los datos:** agregar grandes cantidades de datos no siempre mejora la precisiÃ³n, ya que si los datos de entrada son irrelevantes, pueden ser contraproducentes para alcanzar el resultado deseado. Es esencial realizar una selecciÃ³n de caracterÃ­sticas para identificar las variables que realmente contribuyen a la hipÃ³tesis.
</details>

### ğŸ“– Describe quÃ© son los errores Tipo I y Tipo II y la relaciÃ³n entre ellos.
<details>
  <summary><b>Ver respuesta ğŸ”‘</b></summary>

  El error Tipo I ocurre cuando rechazamos la hipÃ³tesis nula a pesar de que es verdadera. Un ejemplo cotidiano serÃ­a por ejemplo someter a alguien a una prueba de cÃ¡ncer y que el resultado sea positivo, cuando el paciente no tiene la enfermedad.
  
  El error Tipo II sucede al contrario, cuando la hipÃ³tesis nula es falsa pero no conseguimos rechazarla. SerÃ­a concluir que un paciente estÃ¡ sano cuando en realidad sÃ­ tiene la enfermedad.
  
  

  Entre ellos existe una relaciÃ³n inversa, lo que significa que si intentamos reducir la probabilidad de cometer uno, generalmente aumentamos la probabilidad del otro: si ajustamos la prueba para que sea muy sensible (no perdernos ningÃºn caso real), es mÃ¡s probable que cometamos errores de tipo I, mientras que si hacemos la prueba muy estricta, serÃ¡ mÃ¡s probable que cometamos errores de tipo II.
  
  De todas formas, la gravedad de cada error depende del contexto en el que apliquemos la prueba. En una prueba de seguridad en aeropuertos, preferimos un error de tipo I (revisar una maleta de mÃ¡s) que un error de tipo II (dejar pasar algo peligroso). Sin embargo, en el caso de una cirugÃ­a de riesgo, preferimos evitar el error tipo I (operar a alguien que no lo necesita).
</details>

### ğŸ“– Â¿QuÃ© es un Z-test y cuÃ¡ndo lo usarÃ­amos frente a un t-test?
<details>
  <summary><b>Ver respuesta ğŸ”‘</b></summary>

  Un Z-test es una prueba estadÃ­stica que se utiliza para saber si un estadÃ­stico de un grupo de datos es significativamente distinto de lo que se esperaba o de otro grupo, basÃ¡ndose en la distribuciÃ³n normal.
  
  **Â¿CuÃ¡ndo merece la pena usarlo?** Se utiliza cuando el tamaÃ±o de la muestra es grande (> 30 para poder aplicar el Teorema del LÃ­mite Central) o cuando conocemos la varianza o desviaciÃ³n estÃ¡ndar de toda la poblaciÃ³n. En cambio, usar el t-test serÃ¡ Ãºtil cuando el grupo de datos es pequeÃ±o o cuando tenemos que estimar la varianza de la poblaciÃ³n a partir de una muestra.
  
  Como consecuencia de esto, la distribuciÃ³n utilizada en el t-test tiene las â€œcolas mÃ¡s gruesasâ€ (studentâ€™s t-distribution) puesto que al no conocer la varianza de la poblaciÃ³n admitimos una mayor probabilidad de observar valores extremos por puro azar.
  ![Distribuciones](https://github.com/Nachoide100/Preguntas-estad-stica/blob/e1939096bbe27b6ead10f155c22b4d06a21108ee/visualizations/Captura%20de%20pantalla%202026-02-03%20192122.png)

  La distribuciÃ³n roja serÃ­a la t - student. Conforme la n aumentase, esta ser irÃ­a pareciendo a la distribuciÃ³n normal. 
</details>

### ğŸ“– Imagina que tiras una moneda 10 veces y solo observas caras, Â¿cuÃ¡l serÃ­a tu hipÃ³tesis nula y el p-value para comprobar si la moneda estÃ¡ trucada o no?
<details>
  <summary><b>Ver respuesta ğŸ”‘</b></summary>

  La hipÃ³tesis nula es la suposiciÃ³n bÃ¡sica de que cualquier resultado que veamos se debe simplemente al azar, por lo que en nuestro caso serÃ­a que la moneda es justa y que no estÃ¡ trucada. Bajo esta suposiciÃ³n, esperarÃ­amos que la probabilidad de obtener cara en cada lanzamiento fuera del 50%.
  
  Por otro lado, el p-value seÃ±ala cÃ³mo de probable es que el resultado que observamos (10 caras seguidas) haya ocurrido por pura suerte, suponiendo que la moneda no estÃ© trucada (hipÃ³tesis nula).
  
  Ahora, si calculamos la probabilidad de que salgan 10 caras seguidas por azar:
  $$\frac{1}{0.5^{10}}$$
  Obtenemos un valor p aproximado de **0,001**.
  
  Si comparamos ese valor con el lÃ­mite alfa que normalmente se fija en 0,05, vemos que estÃ¡ por debajo, lo que indica una evidencia fuerte contra la hipÃ³tesis nula y un resultado â€œestadÃ­sticamente significativoâ€.
  
  En conclusiÃ³n, dado que obtener 10 caras seguidas es algo extremadamente improbable si la moneda no estÃ¡ trucada, tenemos razones sÃ³lidas para rechazar la idea de que la moneda es normal.
</details>

### ğŸ“– Explica el trasfondo estadÃ­stico del poder.
<details>
  <summary><b>Ver respuesta ğŸ”‘</b></summary>

  El poder estadÃ­stico se puede entender como la capacidad de una prueba para detectar un efecto o cambio real cuando este realmente existe, es decir, la probabilidad de rechazar la hipÃ³tesis nula cuando dicha hipÃ³tesis es falsa. EstÃ¡ muy relacionado con el error de tipo II, puesto que el poder estadÃ­stico pretende evitar no captar un fenÃ³meno que sÃ­ estÃ¡ ocurriendo.
  
  El poder estadÃ­stico se basa en:
  * **El tamaÃ±o de la muestra:** cuantos mÃ¡s datos recolectemos, mÃ¡s poder tendrÃ¡ nuestra prueba de detectar lo que estÃ¡ pasando.
  * **TamaÃ±o del efecto (effect size):** la magnitud de la diferencia que queremos detectar. Es mÃ¡s fÃ¡cil detectar un cambio gigante (aumento de 20% en ventas) que uno diminuto.
  * **Nivel de significaciÃ³n:** el umbral que establecemos para dar un resultado estadÃ­sticamente significativo.
  * **SuposiciÃ³n previa:** generalmente se apunta a tener un poder del 80%, lo que supone aceptar un 20% de probabilidad de no detectar un efecto real.
  
  La utilidad mÃ¡s comÃºn del poder estadÃ­stico es el cÃ¡lculo del tamaÃ±o de la muestra antes de empezar un experimento. Si diseÃ±amos un experimento sin considerar el poder, corremos el riesgo de invertir tiempo y dinero en una prueba que termine siendo inconcluyente, no porque no haya un efecto, sino porque no tenÃ­amos suficientes datos para detectarlo.
</details>

### ğŸ“– Digamos que estÃ¡s comprobando cientos de hipÃ³tesis, cada una con un t-test. Â¿QuÃ© consideraciones deberÃ­amos tomar si hacemos esto?
<details>
  <summary><b>Ver respuesta ğŸ”‘</b></summary>

  Si realizamos cientos de t-test deberemos tener en cuenta los siguientes fenÃ³menos:
  * **Error de Tipo I:** si hacemos un solo test solemos aceptar un margen de error del 5%, pero al hacer cientos de pruebas el riesgo de obtener un resultado por azar se acumula, lo que aumenta en gran cantidad la probabilidad de cometer un falso positivo.
  * **Data snooping:** existe un dicho que dice que â€œSi torturas los datos lo suficiente, tarde o temprano confesarÃ¡nâ€. Esto quiere decir que si buscamos patrones en una base de datos haciendo cientos de preguntas distintas sin un plan previo, acabaremos encontrando algo que nos parezca interesante, pero que en realidad es solo ruido estadÃ­stico.
  
  Entre las principales medidas que podemos tomar para evitar estos problemas son la **correcciÃ³n de Bonferroni** (dividir el nivel de error por el nÃºmero de pruebas a realizar) y el **Holdout Set** (guardar datos de reserva para una comprobaciÃ³n en datos nuevos una vez pensamos que hemos encontrado algo).
</details>

### ğŸ“– Â¿En quÃ© consiste el compromiso entre sesgo y varianza (bias-variance trade-off) y cÃ³mo influye en el fenÃ³meno del sobreajuste (overfitting)?
<details>
  <summary><b>Ver respuesta ğŸ”‘</b></summary>

Existe un relaciÃ³n inversa entre ellos: si intentamos reducir el sesgo (haciendo el modelo mÃ¡s complejo), la varianza tiende a subir automÃ¡ticamente. Por el contrario, si intentamos que el modelo sea muy estable y tenga poca varianza, probablemente serÃ¡ demasiado simple y aumentarÃ¡ el sesgo. 

El fenÃ³meno del sobreajuste ocurre cuando perdemos el equilibrio y dejamos que la varianza aumente drÃ¡sticamente. Esto provoca un modelo â€œdemasiado flexibleâ€ que aprende tan bien los datos de entrenamiento que incluye en su lÃ³gica los errores aleatorios y el ruido que no se repetirÃ¡n el futuro. 

De este modo, si miramos los resultados del enternamiento, se acercarÃ¡n mucho al objetivo real pero al presentarle al modelo datos nuevos que nunca haya visto, su rendimiento caerÃ¡ drÃ¡sticamente porque esos datos nuevos no presentan ese â€œruidoâ€ del cual ha aprendido en los datos de entrenamiento. 

Para evitar el sobreajuste, debemos aceptar un poco mÃ¡s de sesgo (modelo algo mÃ¡s simple) a cambio de reducir la varianza, asegurando asÃ­ que nuestra mÃ¡quina puede generalizar lo aprendido en situaciones y conjuntos de datos nuevos.
</details>

### ğŸ“– Explica detalladamente quÃ© es un valor p (p-value) y por quÃ© un resultado estadÃ­sticamente significativo no siempre implica una importancia prÃ¡ctica para el negocio.
<details>
  <summary><b>Ver respuesta ğŸ”‘</b></summary>

El p - value es la probabilidad de que, aceptando la hipÃ³tesis nula, el resultado esperado se de por casualidad. 

Si el p valor es bajo (menor o igual que 0,05) significa que es muy poco probable que el azar sea responsable y por tanto rechazaremos la hipÃ³tesis nula y concluiremos que el resultado es â€œestadÃ­sticamente significativoâ€. Si por el contrario el valor p es mayor a 0,05, significa que lo que observamos entra dentro de lo que el azar podrÃ­a poducir normalmente. 

Uno de los aspectos clave del p - value es que solo nos indica si el resultado es debido a un efecto real, pero no indica el tamaÃ±o de ese efecto. Esto supone que aplicar una medida validada por el p - value provoque una diferencia tan pequeÃ±a que no tenga sentido para el negocio.
</details>

### ğŸ“– Â¿QuÃ© es la multicolinealidad en un modelo de regresiÃ³n lineal mÃºltiple y quÃ© impacto tiene sobre la estabilidad y la interpretaciÃ³n de los coeficientes de las variables independientes?
<details>
  <summary><b>Ver respuesta ğŸ”‘</b></summary>

La multicolinealidad es una condiciÃ³n que ocurre en los modelos estadÃ­sticos cuando dos o mÃ¡s de las variables que usas para predecir un resultado estÃ¡n fuertemente relacionadas entre sÃ­. 

Cuando existe multicolinealidad, el modelo se vuelve matemÃ¡ticamente inestable, lo que puede provocar que cualquier cambio mÃ­nimo en los datos de entrada deriven en cambios drÃ¡sticos en los resultados del modelo, lo que hace que las conclusiones sean poco fiables. 

El problema mÃ¡s grande es que este fenÃ³meno impide saber quÃ© variable es la verdadera responsable del resultado, ya que las variables correlacionadas tienden a â€œcancelarseâ€ entre sÃ­ en los cÃ¡lculos. AdemÃ¡s, la multicolinealidad infla el error estÃ¡ndar (mayor inestabilidad), lo que significa que el modelo pierde mucha precisiÃ³n al tratar de estimar quÃ© tan importante es realmente cada factor.
</details>


### ğŸ“– Â¿QuÃ© es la multicolinealidad en un modelo de regresiÃ³n lineal mÃºltiple y quÃ© impacto tiene sobre la estabilidad y la interpretaciÃ³n de los coeficientes de las variables independientes?
<details>
  <summary><b>Ver respuesta ğŸ”‘</b></summary>

La multicolinealidad es una condiciÃ³n que ocurre en los modelos estadÃ­sticos cuando dos o mÃ¡s de las variables que usas para predecir un resultado estÃ¡n fuertemente relacionadas entre sÃ­. 

Cuando existe multicolinealidad, el modelo se vuelve matemÃ¡ticamente inestable, lo que puede provocar que cualquier cambio mÃ­nimo en los datos de entrada deriven en cambios drÃ¡sticos en los resultados del modelo, lo que hace que las conclusiones sean poco fiables. 

El problema mÃ¡s grande es que este fenÃ³meno impide saber quÃ© variable es la verdadera responsable del resultado, ya que las variables correlacionadas tienden a â€œcancelarseâ€ entre sÃ­ en los cÃ¡lculos. AdemÃ¡s, la multicolinealidad infla el error estÃ¡ndar (mayor inestabilidad), lo que significa que el modelo pierde mucha precisiÃ³n al tratar de estimar quÃ© tan importante es realmente cada factor.
</details>

---

## ğŸŸ¡ Nivel: Intermedio

---

## ğŸ”´ Nivel: DifÃ­cil

<p align="right">(<a href="#-wiki-de-estadÃ­stica-aplicada">Volver arriba â¬†ï¸</a>)</p>


